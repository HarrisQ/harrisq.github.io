{
  "hash": "3964539462dc92ab670d35b8a484eb9a",
  "result": {
    "markdown": "---\ntitle: A No Nonsense Guide on how to use an M-Series Mac GPU with PyTorch\nsubtitle: M-Series Macs is better than saying M1/M2 Macs\ndescription: Squeezing out that extra performance.\nimage: ../images/8_how_to_use_apple_gpu_with_pytorch/thumbnail.png\nauthor: Salman Naqvi\ndate: 2023-01-26\ncategories: [PyTorch]\nnumber-sections: true\nopen-graph:\n  description: Squeezing out that extra performance.\n  image: ../images/8_how_to_use_apple_gpu_with_pytorch/thumbnail.png\ntwitter-card:\n  description: Squeezing out that extra performance.\n  image: ../images/8_how_to_use_apple_gpu_with_pytorch/thumbnail.png\n---\n\n_This blog post was updated on **Saturday, 28 January 2023**._\n\n![](../images/8_how_to_use_apple_gpu_with_pytorch/thumbnail.png){fig-alt=\"A picture of a snake that has taken a bite out of an apple, and whose tail is a burning torch.\"}\n\nIf you have one of those fancy Macs with an M-Series chip (M1/M2, etc.), here's how to make use of its GPU in PyTorch for increased performance.\n\nIt's a bit annoying and a little tedious, but here we go.\n\n## Requirements\n\n- Have an M-Series chip\n- Have at least PyTorch 1.12\n- Have at least macOS Monterey 12.3\n\n## Installing PyTorch\n\nInstall PyTorch as you usually would. Just make sure it's PyTorch 1.12.\n\n```bash\n# Installing with Pip.\n$ pip3 install torch torchvision torchaudio\n\n# Installing using Conda.\n$ conda install pytorch torchvision torchaudio -c pytorch\n```\nBy using these commands, the latest version of the library is installed so there is no need to specify the version number.\n\nHowever, if you have an existing installation, you can run the following Pip command instead.\n```bash\n$ pip3 install --upgrade torch torchvision torchaudio\n```\n\n## Import PyTorch\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport torch\n```\n:::\n\n\n## Check Requirements are Met\n\nBelow is a convenient code snippet taken from the PyTorch documentation that checks whether requirements are met.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nif not torch.backends.mps.is_available():\n    if not torch.backends.mps.is_built():\n        print(\"MPS not available because the current PyTorch install was not built with MPS enabled.\")\n    else:\n        print(\"MPS not available because the current MacOS version is not 12.3+ and/or you do not have an MPS-enabled device on this machine.\")\n```\n:::\n\n\nIf neither of the two above messages print, you're good to go!\n\n## The Annoying Part: Enabling the GPU\n\nAs far as I know, you must explicitly enable the use of the GPU for whatever model or tensor you wish to use the GPU for.\n\nThere are different ways you can do this.\n\n\n\n**Use a string.**\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nt = torch.tensor([1, 2, 3], device='mps')\n```\n:::\n\n\n::: {.cell execution_count=5}\n\n::: {.cell-output .cell-output-display execution_count=5}\n\n  > `tensor([1, 2, 3], device='mps:0')`\n  \n:::\n:::\n\n\n**Store as a variable.**\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndevice='mps'\nt = torch.tensor([1, 2, 3], device=device)\n```\n:::\n\n\n::: {.cell execution_count=7}\n\n::: {.cell-output .cell-output-display execution_count=7}\n\n  > `tensor([1, 2, 3], device='mps:0')`\n  \n:::\n:::\n\n\n**Convert existing objects.** \n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nt = torch.tensor([1, 2, 3])\nt.to(device)\n```\n:::\n\n\n::: {.cell execution_count=9}\n\n::: {.cell-output .cell-output-display execution_count=9}\n\n  > `tensor([1, 2, 3], device='mps:0')` \n  \n:::\n:::\n\n\nNote that converting existing objects creates a copy and does not modify the original.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nt\n```\n:::\n\n\n::: {.cell execution_count=11}\n\n::: {.cell-output .cell-output-display execution_count=11}\n\n  > `tensor([1, 2, 3])` \n  \n:::\n:::\n\n\nThough the above operations have been performed on tensors, they can also be performed on models.\n\n## Points to Note\n\n- GPU enabled means operations are done on the GPU.\n\n- A GPU enabled tensor can only perform operations with another GPU enabled tensor.\n\n- As of writing this, GPU support is still in its early stages. So certain features are unsupported and further optimizations await.\n\n## Relevant Links {.unnumbered}\nRelevant links:\n\n* Installing PyTorch: [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/) \n\n* Docs on using GPU: [https://pytorch.org/docs/stable/notes/mps.html](https://pytorch.org/docs/stable/notes/mps.html)\n\n* Performance gains (note that nightly builds are no longer needed): [https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)\n\n## Closing Words {.unnumbered}\n\nIf you have any comments, questions, suggestions, feedback, criticisms, or corrections, please do post them down in the comment section below!\n\n",
    "supporting": [
      "8_how_to_use_apple_gpu_with_pytorch_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}