---
author: Harris Quach
title: "Outer Product of Canonical Gradients"
# image: ../images/coming_soon/thumbnail.png
description: " "
bibliography: sdr.bib
date:  "`r format(Sys.time(), '%d %b %Y')`"
format: 
  html:      
    code_download: false
    toc: true 
---

<!-- Google tag (gtag.js) -->

<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-KY1JY0C53S"></script> -->

<!-- <script> -->

<!--   window.dataLayer = window.dataLayer || []; -->

<!--   function gtag(){dataLayer.push(arguments);} -->

<!--   gtag('js', new Date()); -->

<!--   gtag('config', 'G-KY1JY0C53S'); -->

<!-- </script> -->

```{r setup,message=FALSE,echo=FALSE}
library(knitr)
# knitr::opts_chunk$set(dev.args = list(png = list(type = "cairo")))
# library(pander)
# library(Cairo)
```

```{r pkgs, eval=FALSE,echo=FALSE}
# pkgs <- c("lme4","glmmADMB","sos","blme","RLRsim","ggplot2", "MEMSS")
# i1 <- installed.packages()
# pkgs <- setdiff(pkgs, rownames(i1))
# repos <- c("http://glmmadmb.r-forge.r-project.org/repos",
#             getOption("repos"))
# if (length(pkgs)>0) 
#     install.packages(pkgs,repos=repos, type="source")
```

# Introduction

Place Holder for OPCG

Sufficient Dimension Reduction (SDR) is an area of statistics that
focuses on reducing high dimensional data to a just a few features that
reflect, or summarize, all the available information about a specific outcome of interest.
In data science parlance, SDR can be considered methods for "supervised dimension reduction" or "supervised learning".

Ideally, the supervised features will be more interpretable than trying to use the entire set of predictors. Then any subsequent model built upon the supervised features should be more interpretable as well. In terms of interpretability, the supervised features are easier to visualize, since they are lower dimensional summaries and we only have a few to consider. We can plot the supervised features against the outcome in 1d, 2d, and 3d graphics, which can help build a better understanding of the relationship between the outcome and predictors. 


# An Illustration

To illustrate the objective of SDR methods, we can look at a simple example. 
Let $X = (X_1, X_2) \in [0,1]^2$ be a bivariate predictor in the unit square and let $Y \in \R$ be a quadratic function of $X_1$ only. 
Then, if $\beta = (1,0) \in \R^2$, the outcome $Y$ can be expressed as $Y = \beta^\top X$.

![sdr plot](../images/sdr/sdr_plot.png){width=40% fig-align="center"}


For $$
\begin{split}
Y \indep X \mid \beta^\top X   
\end{split}
$$
