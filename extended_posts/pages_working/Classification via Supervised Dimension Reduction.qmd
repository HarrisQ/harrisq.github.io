---
author: Harris Quach
title: "Classification via Supervised Dimension Reduction"
# image: ../images/coming_soon/thumbnail.png
description: " "
bibliography: sdr.bib
date:  "`r format(Sys.time(), '%d %b %Y')`"
format: 
  html:      
    code_download: false
    toc: true 
---

<!-- Google tag (gtag.js) -->

<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-KY1JY0C53S"></script> -->

<!-- <script> -->

<!--   window.dataLayer = window.dataLayer || []; -->

<!--   function gtag(){dataLayer.push(arguments);} -->

<!--   gtag('js', new Date()); -->

<!--   gtag('config', 'G-KY1JY0C53S'); -->

<!-- </script> -->

```{r setup,message=FALSE,echo=FALSE}
library(knitr)
# knitr::opts_chunk$set(dev.args = list(png = list(type = "cairo")))
# library(pander)
# library(Cairo)
```

```{r pkgs, eval=FALSE,echo=FALSE}
# pkgs <- c("lme4","glmmADMB","sos","blme","RLRsim","ggplot2", "MEMSS")
# i1 <- installed.packages()
# pkgs <- setdiff(pkgs, rownames(i1))
# repos <- c("http://glmmadmb.r-forge.r-project.org/repos",
#             getOption("repos"))
# if (length(pkgs)>0) 
#     install.packages(pkgs,repos=repos, type="source")
```

A popular use of Sufficient Dimension Reduction (SDR) methods is for supervised feature construction in classification problems. The general procedure is to reduce a large collection of variables into a few features related to the endpoint/outcome. This relatively smaller set of informative features is used to construct summaries statistics, upon which we perform classification.   

The effectiveness of using informative features for classification explains the numerous SDR approaches developed to  


# Understanding Functional Sliced Inverse Regression (FSIR)

Functional Sliced Inverse Regression (FSIR) is an extension of the classical Sliced Inverse Regression (SIR), tailored for functional data. Functional data arises when the predictors are not scalar or vector values but functions, such as curves or trajectories over a continuous domain. This fundamental difference necessitates specialized methods like FSIR, as functional data requires handling infinite-dimensional spaces and smooth trajectories, unlike finite-dimensional Euclidean data.

## Motivation

In regression problems with functional predictors, the goal is to understand how a response variable $Y$ depends on a set of functional predictors $X(t)$, where $t$ represents a continuous domain (e.g., time, wavelength). Unlike Euclidean data, where predictors are represented as points or vectors in finite-dimensional space, functional data consists of entire functions observed over a continuum. Standard dimension reduction techniques may not be directly applicable due to the infinite-dimensional nature of functional predictors. FSIR adapts the principles of SIR to handle this complexity.

FSIR identifies directions in the functional predictor space that are most informative about the response variable. These directions, referred to as **effective dimension reduction (EDR) directions**, reduce the functional data to a finite-dimensional subspace while retaining the essential relationship between $Y$ and $X(t)$.

## The FSIR Algorithm

FSIR builds on the classical SIR framework but incorporates functional data concepts. The algorithm can be summarized as follows:

### Steps for Implementation

1. **Center and standardize the functional predictors:**
   - Compute the mean function of $X(t)$ across all observations.
   - Subtract the mean function from each $X(t)$ to center the data.
   - Standardize the data to have unit variance over the domain $t$.

2. **Slice the response variable $Y$:**
   - Divide the range of $Y$ into $H$ non-overlapping slices, typically based on quantiles.
   - Assign each observation to a slice based on the value of $Y$.

3. **Compute mean functions for each slice:**
   - For each slice $h$, calculate the mean function $m_h(t)$ of the functional predictors $X(t)$ belonging to that slice.

4. **Estimate the covariance operator:**
   - Calculate the covariance operator of the mean functions $m_h(t)$ across slices. This captures the variation in $X(t)$ that corresponds to variations in $Y$.

5. **Perform eigen-decomposition:**
   - Perform eigen-decomposition on the covariance operator to extract its leading eigenfunctions.
   - These eigenfunctions represent the functional EDR directions.

6. **Project the functional data:**
   - Project each functional predictor $X(t)$ onto the leading eigenfunctions to obtain a finite-dimensional representation.

7. **Model the reduced representation:**
   - Use the reduced representation to model the relationship between $Y$ and $X(t)$ using appropriate regression or classification techniques.

## Key Assumptions

1. **Linearity condition:** The marginal distribution of $X(t)$ is such that any linear combination of $X(t)$ is approximately normally distributed. This ensures that slicing captures the relevant information about $Y$.

2. **Sufficient dimension reduction (SDR):** The relationship between $Y$ and $X(t)$ is fully captured by a finite-dimensional projection of $X(t)$. This assumption parallels that for Euclidean data but must account for the infinite-dimensional nature of functional predictors.

## Applications

FSIR is widely applied in fields such as:
- **Neuroscience:** To analyze brain activity curves and relate them to cognitive outcomes.
- **Environmental science:** To model relationships between environmental variables (e.g., temperature curves) and ecological responses.
- **Finance:** To study the impact of functional predictors like stock price trajectories on financial outcomes.

## Example

Consider a dataset with functional predictors $X(t)$ representing temperature curves over a day and a continuous response $Y$ indicating crop yield. Using FSIR, we may find that only a few functional EDR directions explain the majority of the relationship between $Y$ and $X(t)$. This enables us to reduce the problem from an infinite-dimensional regression to a finite-dimensional one, simplifying analysis and interpretation.

## Limitations

- **Dependence on slicing:** The choice of slicing method and the number of slices can influence the results.
- **Linearity assumption:** Violations of the linearity condition can lead to inaccurate estimates of functional EDR directions.
- **Complex interactions:** FSIR may struggle with capturing complex nonlinear interactions among functional predictors.

## Further Reading

For a deeper dive into the theoretical foundations and practical applications of FSIR, consider the following references:

1. Ferr√©, L., & Yao, A. F. (2003). "Functional sliced inverse regression analysis." *Statistics*, 37(6), 475-488.
2. Ramsay, J. O., & Silverman, B. W. (2005). *Functional Data Analysis*. Springer.
3. Li, B., & Hsing, T. (2010). "Sufficient dimension reduction for functional data." *Annals of Statistics*, 38(5), 332-354.

FSIR provides a powerful tool for exploring and simplifying regression problems involving functional data, enabling better understanding and interpretation of complex relationships.

